{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7: Neural Nets Advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset downloading\n",
    "Download one of the small images dataset: [MNIST](http://yann.lecun.com/exdb/mnist/), [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist), [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html). You can find the list of all available datasets by the [link](https://pytorch.org/vision/stable/datasets.html). Help:\n",
    "\n",
    "```python\n",
    "training_data = torchvision.datasets.NAME_OF_THE_DATASET(root=\"data\", train=True, download=True, \n",
    "                                                  transform=torchvision.transforms.ToTensor())\n",
    "test_data = ...\n",
    "```\n",
    "\n",
    "Check your data folder and find downloaded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place for code\n",
    "import torch, torchvision\n",
    "training_data = torchvision.datasets.FashionMNIST(root=\"data\", train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "test_data = torchvision.datasets.FashionMNIST(root=\"data\", train=False, download=True, transform=torchvision.transforms.ToTensor())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Printing\n",
    "Print some image shape and label. Datasets don't contain label names (only indexes). Use \n",
    "\n",
    "```python\n",
    "label_map = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']  # CIFAR10\n",
    "label_map = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']  # FashionMNIST\n",
    "img, label = training_data[image_index]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.1608, 0.7373, 0.4039, 0.2118, 0.1882, 0.1686,\n          0.3412, 0.6588, 0.5216, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000, 0.1922,\n          0.5333, 0.8588, 0.8471, 0.8941, 0.9255, 1.0000, 1.0000, 1.0000,\n          1.0000, 0.8510, 0.8431, 0.9961, 0.9059, 0.6275, 0.1765, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0549, 0.6902, 0.8706,\n          0.8784, 0.8314, 0.7961, 0.7765, 0.7686, 0.7843, 0.8431, 0.8000,\n          0.7922, 0.7882, 0.7882, 0.7882, 0.8196, 0.8549, 0.8784, 0.6431,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7373, 0.8588, 0.7843,\n          0.7765, 0.7922, 0.7765, 0.7804, 0.7804, 0.7882, 0.7686, 0.7765,\n          0.7765, 0.7843, 0.7843, 0.7843, 0.7843, 0.7882, 0.7843, 0.8824,\n          0.1608, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.8588, 0.7804, 0.7961,\n          0.7961, 0.8314, 0.9333, 0.9725, 0.9804, 0.9608, 0.9765, 0.9647,\n          0.9686, 0.9882, 0.9725, 0.9216, 0.8118, 0.7961, 0.7961, 0.8706,\n          0.5490, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.4549, 0.8863, 0.8078, 0.8000,\n          0.8118, 0.8000, 0.3961, 0.2941, 0.1843, 0.2863, 0.1882, 0.1961,\n          0.1765, 0.2000, 0.2471, 0.4431, 0.8706, 0.7922, 0.8078, 0.8627,\n          0.8784, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.7843, 0.8706, 0.8196, 0.7961,\n          0.8431, 0.7843, 0.0000, 0.2745, 0.3843, 0.0000, 0.4039, 0.2314,\n          0.2667, 0.2784, 0.1922, 0.0000, 0.8588, 0.8078, 0.8392, 0.8235,\n          0.9804, 0.1490, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.9686, 0.8549, 0.8314, 0.8235,\n          0.8431, 0.8392, 0.0000, 0.9961, 0.9529, 0.5451, 1.0000, 0.6824,\n          0.9843, 1.0000, 0.8039, 0.0000, 0.8431, 0.8510, 0.8392, 0.8157,\n          0.8627, 0.3725, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.1765, 0.8863, 0.8392, 0.8392, 0.8431,\n          0.8784, 0.8039, 0.0000, 0.1647, 0.1373, 0.2353, 0.0627, 0.0667,\n          0.0471, 0.0510, 0.2745, 0.0000, 0.7412, 0.8471, 0.8314, 0.8078,\n          0.8314, 0.6118, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.6431, 0.9216, 0.8392, 0.8275, 0.8627,\n          0.8471, 0.7882, 0.2039, 0.2784, 0.3490, 0.3686, 0.3255, 0.3059,\n          0.2745, 0.2980, 0.3608, 0.3412, 0.8078, 0.8118, 0.8706, 0.8353,\n          0.8588, 0.8157, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.4157, 0.7333, 0.8745, 0.9294, 0.9725,\n          0.8275, 0.7765, 0.9882, 0.9804, 0.9725, 0.9608, 0.9725, 0.9882,\n          0.9922, 0.9804, 0.9882, 0.9373, 0.7882, 0.8314, 0.8824, 0.8431,\n          0.7569, 0.4431, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0667, 0.2118, 0.6235,\n          0.8706, 0.7569, 0.8157, 0.7529, 0.7725, 0.7843, 0.7843, 0.7843,\n          0.7843, 0.7882, 0.7961, 0.7647, 0.8235, 0.6471, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1843,\n          0.8824, 0.7529, 0.8392, 0.7961, 0.8078, 0.8000, 0.8000, 0.8039,\n          0.8078, 0.8000, 0.8314, 0.7725, 0.8549, 0.4196, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0235, 0.0000, 0.1804,\n          0.8314, 0.7647, 0.8314, 0.7922, 0.8078, 0.8039, 0.8000, 0.8039,\n          0.8078, 0.8000, 0.8314, 0.7843, 0.8549, 0.3569, 0.0000, 0.0118,\n          0.0039, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0431,\n          0.7725, 0.7804, 0.8039, 0.7922, 0.8039, 0.8078, 0.8000, 0.8039,\n          0.8118, 0.8000, 0.8039, 0.8039, 0.8549, 0.3020, 0.0000, 0.0196,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.0078,\n          0.7490, 0.7765, 0.7882, 0.8039, 0.8078, 0.8039, 0.8039, 0.8078,\n          0.8196, 0.8078, 0.7804, 0.8196, 0.8588, 0.2902, 0.0000, 0.0196,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000,\n          0.7373, 0.7725, 0.7843, 0.8118, 0.8118, 0.8000, 0.8118, 0.8118,\n          0.8235, 0.8157, 0.7765, 0.8118, 0.8667, 0.2824, 0.0000, 0.0157,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000,\n          0.8431, 0.7765, 0.7961, 0.8078, 0.8157, 0.8039, 0.8118, 0.8118,\n          0.8235, 0.8157, 0.7843, 0.7922, 0.8706, 0.2941, 0.0000, 0.0157,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n          0.8314, 0.7765, 0.8196, 0.8078, 0.8196, 0.8078, 0.8157, 0.8118,\n          0.8275, 0.8078, 0.8039, 0.7765, 0.8667, 0.3137, 0.0000, 0.0118,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n          0.8000, 0.7882, 0.8039, 0.8157, 0.8118, 0.8039, 0.8275, 0.8039,\n          0.8235, 0.8235, 0.8196, 0.7647, 0.8667, 0.3765, 0.0000, 0.0118,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n          0.7922, 0.7882, 0.8039, 0.8196, 0.8118, 0.8039, 0.8353, 0.8078,\n          0.8235, 0.8196, 0.8235, 0.7608, 0.8510, 0.4118, 0.0000, 0.0078,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n          0.8000, 0.8000, 0.8039, 0.8157, 0.8118, 0.8039, 0.8431, 0.8118,\n          0.8235, 0.8157, 0.8275, 0.7569, 0.8353, 0.4510, 0.0000, 0.0078,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.8000, 0.8118, 0.8118, 0.8157, 0.8078, 0.8078, 0.8431, 0.8235,\n          0.8235, 0.8118, 0.8314, 0.7647, 0.8235, 0.4627, 0.0000, 0.0078,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n          0.7765, 0.8157, 0.8157, 0.8157, 0.8000, 0.8118, 0.8314, 0.8314,\n          0.8235, 0.8118, 0.8275, 0.7686, 0.8118, 0.4745, 0.0000, 0.0039,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n          0.7765, 0.8235, 0.8118, 0.8157, 0.8078, 0.8196, 0.8353, 0.8314,\n          0.8275, 0.8118, 0.8235, 0.7725, 0.8118, 0.4863, 0.0000, 0.0039,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.6745, 0.8235, 0.7961, 0.7882, 0.7804, 0.8000, 0.8118, 0.8039,\n          0.8000, 0.7882, 0.8039, 0.7725, 0.8078, 0.4980, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.7373, 0.8667, 0.8392, 0.9176, 0.9255, 0.9333, 0.9569, 0.9569,\n          0.9569, 0.9412, 0.9529, 0.8392, 0.8784, 0.6353, 0.0000, 0.0078,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n          0.5451, 0.5725, 0.5098, 0.5294, 0.5294, 0.5373, 0.4902, 0.4863,\n          0.4902, 0.4745, 0.4667, 0.4471, 0.5098, 0.2980, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000]]]) 0\n"
     ]
    }
   ],
   "source": [
    "# place for code\n",
    "image_index = 1\n",
    "label_map = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']  # CIFAR10\n",
    "label_map = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']  # FashionMNIST\n",
    "img, label = training_data[image_index]\n",
    "\n",
    "print(img, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plotting\n",
    "Display several images from the dataset. Help:\n",
    "\n",
    "```python\n",
    "img1 = torchvision.transforms.ToPILImage()(img)\n",
    "plt.imshow(img1)\n",
    "plt.title(f'class = {label_map[label]}')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place for code\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img1 = torchvision.transforms.ToPILImage()(img)\n",
    "plt.imshow(img1)\n",
    "plt.title(f'class = {label_map[label]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Neural Net Structure\n",
    "Define neural net structure, loss criterion and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # first argument - input channel count (3 - for color, 1 - for grayscale images)\n",
    "        # second argument - number of output channels (number of different kernels to use)\n",
    "        # third argument - kernel size\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=..., kernel_size=...)\n",
    "        \n",
    "        # takes max from 2x2 subimages\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # define one more convolution layers\n",
    "        # output size of previous layers must match input size of next layers\n",
    "        self.conv2 = ...\n",
    "        \n",
    "        # define fully connected linear layer\n",
    "        # first argument - input size (channel_num * width * height - for images)\n",
    "        #second argument - output size\n",
    "        self.fc1 = torch.nn.Linear(in_features=..., out_features=...)\n",
    "        \n",
    "        # define several more fully connected linear layers\n",
    "        # output size of previous layers must match input size of next layers\n",
    "        # usually output size decreases from layer to layer\n",
    "        self.fc2 = ...\n",
    "        self.fc3 = ...  # output size of last layer should match classes count\n",
    "\n",
    "    def forward(self, x):\n",
    "        print('Initial input shape:', x.shape)\n",
    "        \n",
    "        # apply self.conv1 layer to the input\n",
    "        x = self.conv1(x)\n",
    "        print('Output of conv1 shape:', x.shape)\n",
    "        \n",
    "        # apply F.relu activation function to the x\n",
    "        x = ....\n",
    "        \n",
    "        # apply the subsampling layer self.pool and print the resulting shape\n",
    "        x = ....\n",
    "        print('Output of first subsampling shape:', x.shape)\n",
    "        \n",
    "        # apply second convolution layer conv2, F.relu and self.pool (print shapes to debug errors)\n",
    "        ....\n",
    "        \n",
    "        # linearize output of previous layer, but keep batch dimension\n",
    "        # view first argument - batch size (-1 - default), second - linearized size of x\n",
    "        x = x.view(-1, ....)\n",
    "        \n",
    "        # apply fully connected layer 1 \n",
    "        x = ...\n",
    "        \n",
    "        # apply F.relu activation function to the x\n",
    "        x = ...\n",
    "\n",
    "        # apply fully connected layer 2\n",
    "        x = ...\n",
    "        \n",
    "        # apply F.relu activation function to the x\n",
    "        x = ...\n",
    "\n",
    "        # apply fully connected layer 3\n",
    "        x = ...\n",
    "        \n",
    "        # we don't need activation after last layer, because we use softmax with exponents\n",
    "\n",
    "        # return result\n",
    "        return x\n",
    "\n",
    "# construct neural network\n",
    "net = Net()\n",
    "\n",
    "# define loss criterion\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=...., momentum=....)\n",
    "\n",
    "# define data loaders\n",
    "trainloader = torch.utils.data.DataLoader(training_data, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training\n",
    "\n",
    "Train your model using gradient descent method. Choose learning_rate and epoch count to reach the loss = 0.098"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_loss = 0\n",
    "for epoch in range(...):  # loop over the dataset multiple times (epochs)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for cycle, data_batch in enumerate(trainloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        x_batch, label_batch = data_batch\n",
    "\n",
    "        # forward step\n",
    "        output = net(x_batch)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = criterion(output, label_batch)\n",
    "        \n",
    "        # calculate gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # change weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Compute mean loss for several cycles using exponential moving average and alpha = 0.01\n",
    "        # (use loss.item() to detach gradients)\n",
    "        mean_loss = ....\n",
    "        \n",
    "        # Print loss each 200 cycle\n",
    "        if cycle % 200 == 0:\n",
    "            print(f'epoch = {epoch} cycle = {cycle}, loss = {mean_loss}')\n",
    "\n",
    "print('Training finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(net.state_dict(), 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previously saved model\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load('model.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prediction\n",
    "For several images print true classes and predicted probabilities (for each class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 3\n",
    "img, label = training_data[image_index]\n",
    "print('true class =', label_map[label])\n",
    "\n",
    "# Network requires batchs as input. Build a batch with size 1 from image\n",
    "batch = torch.unsqueeze(img, 0)\n",
    "print('Batch shape =', batch.shape)\n",
    "\n",
    "output = net(batch)\n",
    "# convert output to probabilities using F.softmax function (add extra argument dim=1 to suppress warning)\n",
    "probabilities = ....\n",
    "\n",
    "# print class name and its probability for each class\n",
    "...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd0ed225720166559e7176d3793db16a2fd8d295f725007103b21ac3099d2a89ee8",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}